# Ansible MCP Server - Project Context

## üéØ MVP Definition: Universal Homelab MCP Server

**Core Vision**: This MCP server provides tools and context for AI agents to intelligently manage homelab infrastructure. The AI agent makes decisions based on user requirements and available resources discovered through the MCP.

### Key MVP Requirements:
1. **Context-Aware Infrastructure Discovery**
   - MCP provides tools to discover ALL Proxmox resources (nodes, VMs, storage, networks)
   - Maintains up-to-date inventory of hardware capabilities and current usage
   - AI agents use this context to make informed decisions
   - Regular inventory refresh to ensure accurate state

2. **AI Decision Making**
   - AI agent analyzes user requirements against available resources
   - Makes intelligent choices about VM sizing, node placement, storage allocation
   - Considers current cluster utilization before provisioning
   - Provides recommendations and alternatives when resources are constrained

3. **Tool-Based Operations**
   - MCP provides tools, NOT automation logic
   - AI agent orchestrates tool usage based on context and requirements
   - Clear separation: MCP = tools + context, AI = decision making
   - Universal interface that any MCP-compatible AI can use

4. **Workflow Example**
   - User: "I need a Jenkins server"
   - AI Agent:
     1. Uses MCP to discover current cluster state
     2. Analyzes available resources (CPU, memory, storage)
     3. Determines optimal VM configuration and placement
     4. Uses MCP tools to create and configure the VM
     5. Monitors deployment and adjusts as needed

### Core MCP Components:
1. **Discovery Tools** - Inventory ALL infrastructure:
   - Proxmox cluster resources (VMs, storage, networks)
   - Bare metal servers (via Ansible inventory)
   - External services (Pi-hole, NAS, mail servers)
   - Network devices (routers, switches, bridges)
   - Security posture (open ports, vulnerabilities)

2. **Execution Tools** - Manage hybrid infrastructure:
   - Ansible for bare metal and VM configuration
   - Terraform for VM provisioning
   - Direct API calls for network devices
   - Security scanning integration

3. **Template Library** - Complete infrastructure templates:
   - VM creation (provider-agnostic)
   - Bare metal server configuration
   - Network device setup (routers, bridges)
   - Security hardening playbooks
   - External service deployment (Pi-hole, mail, NAS)

4. **Standard Operating Procedures (SOPs)** - Holistic operations:
   - Infrastructure operations (VMs AND bare metal)
   - Network topology management
   - Security scanning and remediation
   - Failover and redundancy setup
   - Service distribution for resilience

5. **Security Tools** - Continuous security monitoring:
   - Port scanning (nmap integration)
   - Vulnerability scanning
   - Configuration compliance
   - SSL certificate management
   - Access audit logs

### Template Categories:
- **Infrastructure Templates** (Terraform)
  - Create VM with specific resources (`terraform/modules/compute/`)
  - Configure networking and storage (`terraform/modules/network/`)
  - Set up GPU passthrough (`terraform/ollama-gpu-vm/`)
  - Clone from templates (`playbooks/create-vm.yml`)
  
- **Service Templates** (Ansible)
  - Install and configure Jenkins (`playbooks/install-jenkins.yml`)
  - Deploy Ollama with GPU (`playbooks/install-ollama.yml`, `playbooks/configure-ollama-gpu.yml`)
  - WordPress + MySQL + SSL (`playbooks/deploy-wordpress.yml`)
  - Plex/Jellyfin media server (`playbooks/deploy-media-server.yml`)
  - Home Assistant (`playbooks/deploy-home-assistant.yml`)
  - Cloudflare tunnel (`playbooks/setup-cloudflare-tunnel.yml`)
  - Set up monitoring (Prometheus/Grafana)
  - Configure backup solutions
  
- **Configuration Templates** (Ansible)
  - Modify service settings
  - Update Proxmox configurations
  - Manage users and permissions (`playbooks/setup-ollama-ssh.yml`)
  - Configure SSL certificates

### MCP Template Tools:
- `list-templates` - Show available templates by category
- `get-template` - Retrieve a specific template with parameters
- `generate-from-template` - Create customized script from template
- `validate-template` - Check if template is valid for current environment

### SOP System:
**Basic Operations SOPs** (Built into MCP):
- VM Creation: Steps, resource requirements, validation checks
- Network Configuration: VLAN setup, firewall rules, IP allocation
- Storage Management: Disk creation, expansion, backup procedures
- User Management: SSH keys, permissions, access control

**Service-Specific SOPs** (Dynamic):
- Query target VM OS/architecture
- Determine correct binaries/packages
- Provide installation steps adapted to environment
- Include post-installation validation
- Example: Installing Jenkins
  - Detect OS (Ubuntu 22.04, CentOS 8, etc.)
  - Select appropriate Java version
  - Choose Jenkins package for architecture
  - Configure based on available resources

### MCP SOP Tools:
- `query-sop` - Get SOP for specific operation
- `list-sops` - Show all available SOPs
- `get-service-requirements` - Check prerequisites for service installation
- `validate-environment` - Verify environment meets SOP requirements

### How SOPs Guide AI Agents:
1. **User Request**: "Install Jenkins"
2. **AI Agent Workflow**:
   - Query SOP for "install_jenkins"
   - Check prerequisites (Java, memory requirements)
   - Discover existing Jenkins instances
   - Determine target VM OS/architecture
   - Select appropriate installation method
   - Generate customized playbook from templates
   - Execute installation with validation steps
   - Update context with new service details

### What This Means:
- MCP provides: Tools, context, templates, AND procedural knowledge (SOPs)
- AI provides: Intelligence to interpret SOPs, make decisions, and adapt to environment
- Together: User gets intelligent infrastructure automation that follows best practices

## üèóÔ∏è CORE ARCHITECTURE PRINCIPLE: UNIVERSAL PROVIDER AGNOSTICISM

**CRITICAL DESIGN REQUIREMENT**: This MCP server MUST work seamlessly across ALL infrastructure types:

### **Target Infrastructure Environments:**
1. **üè† Local Bare Metal**
   - Physical servers, workstations, Raspberry Pis
   - Direct hardware provisioning and management
   - IPMI, BIOS configuration, hardware discovery

2. **üñ•Ô∏è Local Virtualization**
   - Proxmox VE, VMware vSphere, Hyper-V
   - LXD containers, Docker, Podman
   - Local hypervisor management

3. **‚òÅÔ∏è Cloud Providers**
   - AWS EC2, Azure VMs, GCP Compute Engine
   - Cloud-native services (RDS, Lambda, etc.)
   - Multi-cloud deployments

4. **üîÄ Hybrid Environments**
   - Mixed local + cloud infrastructures
   - Cross-provider workload distribution
   - Unified management across environments

### **Provider-Agnostic Design Patterns:**

#### **1. Universal Resource Abstraction**
All infrastructure operations use provider-neutral resource definitions:

```json
{
  "resource_type": "compute",
  "name": "web-server",
  "specifications": {
    "cpu_cores": 4,
    "memory_gb": 8,
    "storage_gb": 100,
    "network_tier": "standard",
    "os_family": "ubuntu",
    "os_version": "22.04"
  },
  "deployment_preferences": {
    "availability": "high",
    "performance": "balanced",
    "cost_optimization": true
  }
}
```

#### **2. Provider Driver Architecture**
```
User Intent ‚Üí AI Analysis ‚Üí Abstract Config ‚Üí Provider Driver ‚Üí Native API
     ‚Üì             ‚Üì              ‚Üì               ‚Üì            ‚Üì
"Need web server" ‚Üí Resource requirements ‚Üí Standard format ‚Üí Proxmox/AWS/etc ‚Üí Implementation
```

#### **3. Authentication Abstraction**
Universal authentication handles all provider types:
- **SSH Keys**: Bare metal, VMs, containers
- **API Tokens**: Cloud services, appliances
- **Cloud Roles**: AWS IAM, Azure SP, GCP SA
- **Certificates**: Kubernetes, Docker TLS

#### **4. Provider Translation Layer**
Each provider has a translation driver:

**Proxmox Driver**:
```json
{cpu: 4, memory_gb: 8} ‚Üí {cores: 4, memory: 8192, template: 9000}
```

**AWS Driver**:
```json
{cpu: 4, memory_gb: 8} ‚Üí {instance_type: "t3.large", ami: "ami-ubuntu-22.04"}
```

**GCP Driver**:
```json
{cpu: 4, memory_gb: 8} ‚Üí {machine_type: "e2-standard-4", image: "ubuntu-2204-lts"}
```

### **Implementation Requirements:**

#### **1. No Provider Lock-in**
- ‚ùå Never hardcode provider-specific resource types
- ‚ùå Never assume specific infrastructure capabilities
- ‚úÖ Always use abstract resource definitions
- ‚úÖ Support graceful provider migration

#### **2. Capability Detection**
```python
class ProviderCapabilities:
    supports_containers: bool
    supports_gpu: bool
    supports_networking: bool
    max_cpu_cores: int
    max_memory_gb: int
    storage_types: List[str]
```

#### **3. Universal Service Deployment**
Services must deploy anywhere:
```bash
# Same command works on ALL providers
deploy_service {
  "service": "docker",
  "target": "optimal",  # AI picks best available infrastructure
  "requirements": {"cpu": 2, "memory_gb": 4}
}
```

#### **4. Provider-Agnostic Tools**
All MCP tools must work universally:
- `create-compute-resource` (not `create-proxmox-vm`)
- `setup-universal-auth` (handles all auth types)
- `deploy-service` (works on any infrastructure)
- `discover-infrastructure` (finds any provider type)

### **Benefits of This Architecture:**

1. **üîÑ Future-Proof**: Add new providers without changing core logic
2. **üåç Hybrid-Ready**: Mix local and cloud seamlessly  
3. **üí∞ Cost-Flexible**: Move workloads based on cost/performance
4. **üéØ AI-Optimal**: AI chooses best infrastructure automatically
5. **üöÄ Migration-Friendly**: Easy provider transitions
6. **üìà Scalable**: Start local, expand to cloud naturally

### **Current Provider Drivers Implemented:**
- ‚úÖ **Proxmox**: VM creation, management, discovery
- ‚úÖ **LXD**: Container management
- ‚úÖ **Docker**: Container deployment
- ‚úÖ **SSH/Bare Metal**: Direct server management
- üöß **AWS**: (Architecture ready, implementation pending)
- üöß **Azure**: (Architecture ready, implementation pending)
- üöß **GCP**: (Architecture ready, implementation pending)

### **Development Guidelines:**

1. **Always Design Provider-Agnostic First**
   - Start with abstract resource definitions
   - Then implement provider-specific translations
   
2. **Test Multi-Provider Scenarios**
   - Ensure tools work across different infrastructure
   - Validate provider switching capabilities

3. **Document Provider Limitations**
   - Clearly note provider-specific constraints
   - Provide fallback strategies

4. **Extensible Driver System**
   - Make adding new providers straightforward
   - Maintain driver interface consistency

**This architecture ensures the MCP server becomes a truly universal infrastructure automation platform, not just a Proxmox/homelab tool.**

## üìö Documentation & Knowledge Management

**PRIORITY**: The project is accumulating extensive documentation that needs proper organization and management.

### Current Documentation Challenges:
- Multiple large markdown files in repository root
- Scattered knowledge across various files  
- Growing complexity of architecture documentation
- Need for searchable, maintainable knowledge base

### Planned Documentation System:
1. **Phase 1**: Restructure repository docs into organized `docs/` directory
2. **Phase 2**: Deploy self-hosted documentation service (BookStack/Outline)
3. **Phase 3**: Integrate documentation tools into MCP for auto-documentation

### Documentation Service Requirements:
- **Self-hosted** within homelab infrastructure
- **WYSIWYG editing** for non-technical users
- **Search functionality** across all documentation
- **API integration** for automated documentation updates
- **Version control** and change tracking

### MCP Documentation Tools (Future):
- `create-documentation` - Create new documentation pages
- `update-documentation` - Update existing knowledge base
- `search-documentation` - Search procedures and guides  
- `document-infrastructure` - Auto-document discovered resources
- `get-procedure` - Retrieve SOPs and operational guides

See `DOCUMENTATION_STRATEGY.md` for detailed implementation plan.

2. **OS Configuration via Ansible**
   - Use Ansible for ALL OS-level configuration and application deployment
   - Keeps configuration portable across different infrastructure providers
   - Separation of concerns: Terraform = Infrastructure, Ansible = Configuration

3. **Provider Preferences**
   - For Proxmox: Use `bpg/proxmox` provider (more stable than Telmate)
   - Always test with multiple providers when adding new features

## Infrastructure Constraints
- **Proxmox Development Environment**:
  - Max 12 vCPUs per VM (host limitation)
  - Node name: "proxmox" (not "pve")
  - Template ID 9000: ubuntu-cloud-template

## MCP Server Deployment
- **Dev MCP Server**: 192.168.10.102 (for testing)
- **Production MCP Server**: 192.168.10.110
- **Current Dev VM**: 192.168.10.169 (VM ID 100 on Proxmox)
- **Proxmox Host**: 192.168.10.200

**IMPORTANT**: When testing MCP features, use the dev MCP server at 192.168.10.102, NOT local installations!

## üóÑÔ∏è CRITICAL: Inventory Context System (January 25, 2025)
**PRIORITY**: The MCP MUST maintain up-to-date inventory context of all infrastructure resources.

### Core Requirements:
1. **Complete Proxmox Inventory**: VMs, templates, ISOs, storage pools, nodes, networks
2. **Automatic Staleness Detection**: Context expires after configurable time (default: 10 hours)
3. **Background Refresh**: Auto-update stale inventory in background
4. **Tool Blocking**: Block infrastructure tools during inventory refresh to prevent inconsistent state
5. **State Modification Tracking**: All create/modify/delete operations MUST update inventory context immediately

### Implementation Plan:
- Add Proxmox discovery tool to scan: VMs, templates (ID 9000), ISOs, storage, networks
- Create inventory refresh mechanism with configurable staleness threshold
- Implement tool blocking during refresh operations
- Add inventory update hooks to all state-modifying tools
- Store inventory with timestamps in `/inventory/proxmox-resources.json`

### Template VM Management Requirements:
1. **Create Templates**: MCP should be able to create new VM templates with:
   - Pre-configured SSH keys from MCP server
   - Cloud-init ready configuration
   - Standard user accounts and passwords
2. **Store Template Context**: When creating templates, store:
   - Template ID, name, and configuration
   - SSH access credentials
   - Cloud-init settings
   - Default user accounts
3. **Template Discovery**: Automatically discover and catalog existing templates
4. **Clone Configuration**: Store successful clone configurations as reusable templates

### Context Files That Need This:
- `/inventory/proxmox-resources.json` - Complete Proxmox resource inventory
- `/inventory/last-discovery.json` - Discovery timestamps and metadata
- `.env` - Staleness threshold configuration (`INVENTORY_STALENESS_HOURS=10`)

**This is BLOCKING for VM creation - we need to know about template 9000 and all available resources before any infrastructure operations.**

## üì¶ State Management (MVP)
- **Context Storage**: All state stored in `/inventory/` directory
- **Periodic Refresh**: Automatic scans update context every 10 hours
- **Validation**: Compare discovered state vs stored playbook inventory
- **Backup**: Basic ZIP export of entire context for download
- **Credentials**: Stored in `.env` files (user-editable)

## üîÆ Post-MVP Features (Documented)
1. **MCP High Availability** - Redundant MCP servers
2. **Advanced Credential Management** - Vault integration
3. **Audit Logging** - Important for multi-provider compliance
4. **Rate Limiting** - Prevent resource exhaustion
5. **Security Scanning** - Full nmap, vulnerability assessment
6. **Bare Metal Discovery** - Auto-discover physical servers
7. **Multi-Provider Support** - AWS, GCP, Azure drivers
8. **Modern Infrastructure UI** - Service-centric dashboard to replace Proxmox UI
   - Interactive network topology diagrams (React Flow/D3.js)
   - Service grouping instead of resource grouping
   - Drag-and-drop VM organization
   - Visual network flow representation
   - Better than Proxmox's resource-centric organization

## üìö Standard Operating Procedures (SOPs)
The MCP now includes built-in SOPs for common operations. AI agents can query these using:
- `query-sop` - Get detailed steps for any operation (e.g., "create_vm", "install_ollama")
- `list-sops` - List all available procedures
- `get-best-practice` - Get naming conventions, resource allocation guidelines
- `get-error-recovery` - Get recovery steps for common errors

### Example SOP Usage:
```
query-sop operation="create_vm" detailed=true
```

This provides agents with:
1. Step-by-step instructions
2. Validation checks at each step
3. Common issues and solutions
4. Prerequisites and requirements

## üîê Ansible Admin Account Management
**CRITICAL**: All VMs created by MCP now include a standard `ansible-admin` account for consistent access.

### Default Configuration:
- **Username**: `ansible-admin`
- **Access**: Full sudo without password (NOPASSWD)
- **SSH Keys**: MCP's SSH key automatically added
- **Password**: Auto-generated 20-char secure password, encrypted in context

### Credential Management Tools:
- `store-vm-credentials` - Store VM credentials after creation
- `retrieve-vm-credentials` - Get credentials (with optional decryption)
- `generate-secure-password` - Generate passwords for accounts
- `update-context-after-operation` - Update context after any operation
- `list-vm-credentials` - List all VMs with their access info

### Automatic Context Updates:
Every successful operation now updates the MCP context:
- VM creation ‚Üí Stores IP, credentials, resources, purpose
- Service installation ‚Üí Stores endpoints, versions, config
- All credentials encrypted and vaulted

### Example:
```bash
# After VM creation
store-vm-credentials vmId="203" vmName="ollama-server" vmIp="192.168.10.203"

# Retrieve credentials later
retrieve-vm-credentials vmId="203" decrypt=true

# Update context after service install
update-context-after-operation operationType="service_installed" entityId="ollama" updates={endpoint:"http://192.168.10.203:11434", version:"0.1.17"}
```

## üéØ Modular Service SOPs
The MCP now uses a modular service SOP system to avoid duplication:

### Service SOP Structure:
- **Base SOP** (`/src/service-sops/base-service-sop.json`) - Common steps for all services
- **Service-Specific SOPs** (`/src/service-sops/{service}-sop.json`) - Service-specific details

### Available Service SOPs:
- `ollama` - LLM inference server
- `nextcloud` - Self-hosted cloud storage
- `docker` - Container runtime
- More can be added without changing core code

### Service SOP Tools:
- `get-service-sop` - Get complete SOP for any service
- `list-service-sops` - List all available service SOPs
- `compare-service-requirements` - Compare resource needs across services

### Example Usage:
```bash
# Get Ollama installation SOP
get-service-sop serviceName="ollama" section="installation"

# Compare requirements for multiple services
compare-service-requirements services=["ollama", "nextcloud"]

# Check if service already exists
detect-existing-service serviceName="nextcloud"
```

## üìã Template Validation & Compliance
All templates MUST have `ansible-admin` account pre-configured for MCP management.

### Template Requirements:
- **ansible-admin** user with sudo NOPASSWD
- MCP SSH keys in authorized_keys
- cloud-init installed and configured
- Python3, sudo, openssh-server packages

### Template Validation Tools:
- `validate-template` - Check if template meets MCP standards
- `fix-template` - Fix non-compliant templates (add ansible-admin, etc.)
- `discover-templates` - Find and validate all templates
- `create-compliant-template` - Create new MCP-compliant template

### Template Discovery Workflow:
1. **Unknown Template Found** ‚Üí Alert user
2. **Validation Options**:
   - Validate: Test ansible-admin access
   - Fix: Add ansible-admin if missing
   - Delete: Remove if not needed
   - Keep: Mark as legacy/non-compliant

### Example:
```bash
# Discover all templates
discover-templates validateAll=true

# Validate specific template
validate-template templateId="9001"

# Fix non-compliant template
fix-template templateId="9001" issue="no_ansible_admin" action="fix" credentials={username:"root", password:"..."}
```

## üîç Inventory Deviation Management
The MCP now includes advanced inventory deviation detection:

### Deviation Detection Tools:
- `compare-inventory-state` - Compare context vs live inventory, detect new/missing VMs
- `process-deviation` - Handle deviations (accept new VMs, restore missing ones)
- `check-node-capacity` - Verify node has resources for VM placement
- `find-best-node` - Find optimal node for new VM based on resources

### Key Features:
1. **Automatic Deviation Detection**:
   - New VMs trigger alerts asking if expected
   - Missing VMs offer recovery options (backup/terraform/ansible)
   - Resource changes are tracked

2. **Resource Tracking**:
   - Each node's CPU/memory/storage limits and usage
   - Automatic alerts at 80% (warning) and 90% (critical)
   - VM placement validation before creation

3. **Alert Templates**:
   - New VM: Asks for purpose, owner, credentials
   - Missing VM: Offers restore from backup/IaC
   - Resource exhaustion: Prevents new VMs, suggests actions

### Example Workflow:
```
# Check for deviations
compare-inventory-state autoAlert=true updateContext=true

# If new VM found
process-deviation deviationType="new_vm" vmId="203" action="accept" details={purpose:"Test server", owner:"DevOps"}

# Check where to place new VM
find-best-node requiredResources={cores:4, memoryMb:8192, diskGb:100}
```

## Development Philosophy

### Linux-First Approach
- **MVP Focus**: Full Linux/Unix support for homelab environments
- **Target Environment**: Proxmox VE (Debian-based) and Ubuntu VMs
- **Development Platform**: Linux/WSL2
- **Deployment**: Linux containers and VMs
- **Windows/macOS**: Post-MVP consideration

This aligns with typical homelab infrastructure where:
- Proxmox runs on Linux
- Most VMs are Linux-based
- Ansible works natively on Linux
- Container workloads are Linux-based

## üîê Secure Authentication Database
The MCP includes a secure credential management system with encrypted storage:

### Database Structure:
```python
# SQLite database with encryption for sensitive data
credentials.db:
  ‚îú‚îÄ‚îÄ profiles table
  ‚îÇ   ‚îú‚îÄ‚îÄ name (TEXT PRIMARY KEY)
  ‚îÇ   ‚îú‚îÄ‚îÄ data (TEXT) - Encrypted JSON with Proxmox credentials
  ‚îÇ   ‚îú‚îÄ‚îÄ encryption_version (INTEGER)
  ‚îÇ   ‚îú‚îÄ‚îÄ created_at (TIMESTAMP)
  ‚îÇ   ‚îî‚îÄ‚îÄ updated_at (TIMESTAMP)
  ‚îÇ
  ‚îî‚îÄ‚îÄ metadata table
      ‚îú‚îÄ‚îÄ key (TEXT PRIMARY KEY)
      ‚îú‚îÄ‚îÄ value (TEXT)
      ‚îî‚îÄ‚îÄ updated_at (TIMESTAMP)
```

### Credential Security Features:
- **Fernet Encryption**: Industry-standard symmetric encryption
- **Base64 Encoded Storage**: Safe storage in SQLite
- **Profile Management**: Multiple credential profiles (dev, prod, staging)
- **Auto Migration**: Automatic `.env` ‚Üí secure database migration
- **Encrypted Fields**: Passwords and API tokens always encrypted

### Credential Manager API:
```python
# Store credentials securely
await credential_manager.store_credentials("proxmox", {
    "host": "192.168.10.200",
    "username": "root@pam",
    "password": "encrypted_password",
    "api_token": "encrypted_token"
})

# Retrieve with automatic decryption
creds = await credential_manager.get_credentials("proxmox")
```

### API Token Support:
- **Password Auth**: 2-hour session timeout (Proxmox default)
- **API Token Auth**: No timeout, better for automation
- **Auto Token Creation**: Wizard offers to create tokens during setup
- **Token Format**: `user@realm!tokenid=uuid`
- **Token Management**: Create, test, and rotate tokens via MCP

## Current Status (January 30, 2025)

### ‚úÖ COMPLETED: Infrastructure Intelligence + VM Management Platform

1. **üß† AI-Powered Infrastructure Discovery**
   - **Hardware Detection**: GPU discovery with classification (AMD MI50, NVIDIA, Intel)
   - **Smart Filtering**: Natural language queries ("show mysql servers", "vms with 8gb ram")
   - **Resource Analysis**: CPU, memory, storage utilization tracking
   - **Live Inventory**: Real-time Proxmox resource discovery with caching

2. **üéØ Intelligent Deployment Suggestions**
   - **Workload Profiles**: AI training, database, web server, compute, storage
   - **Node Scoring**: Algorithm considers GPU, CPU, memory, current utilization
   - **Smart Recommendations**: "Deploy Ollama on proxmox node - has MI50 GPU"
   - **Custom Requirements**: Override defaults with specific resource needs

3. **üìä Infrastructure Visualization**
   - **ASCII Diagrams**: Beautiful terminal-friendly infrastructure layouts
   - **Resource Charts**: CPU/memory utilization with visual bars
   - **GPU Allocation Maps**: Shows which VMs use which GPUs
   - **Topology Views**: Node ‚Üí VM ‚Üí Service relationships

4. **üöÄ VM Creation & Management (COMPLETE)**
   - **Cloud-Init Integration**: Ubuntu template with ansible-admin user
   - **Intelligent Placement**: Auto-select optimal node based on resources
   - **QEMU Guest Agent**: Pre-installed for Proxmox integration
   - **Service Templates**: Base, development, Docker, AI, web, database
   - **Resource Validation**: Check capacity before VM creation
   - **Full Lifecycle**: Create, start, stop, delete, status monitoring
   - **Automatic Discovery**: Node detection and IP address resolution
   - **Complete Test Coverage**: 14 comprehensive VM creation tests

5. **üöÄ Production Features Implemented**
   - **Comprehensive Test Coverage**: 105+ test cases across all features
   - **Edge Case Handling**: Graceful handling of unusual queries
   - **Type Safety**: Full type hints with dataclasses
   - **Async Architecture**: High-performance async/await throughout

### üîß Technical Implementation Details

#### Core Components:
```python
# Proxmox Discovery Tools
ProxmoxDiscoveryTools:
  - list_nodes()      # Discover cluster nodes
  - list_vms()        # Smart VM filtering
  - discover_hardware() # GPU/CPU/Storage detection
  - suggest_deployment() # AI workload placement
  - generate_diagram()  # Infrastructure visualization

# Hardware Classification
ProxmoxAPIClient:
  - discover_node_hardware() # Complete hardware inventory
  - _classify_gpu_capabilities() # AMD MI50, NVIDIA Tesla, etc.
  - _discover_storage_devices() # NVMe, SSD, HDD detection

# Visualization Engine
InfrastructureVisualizer:
  - generate_topology_diagram() # ASCII network layout
  - generate_resource_utilization() # Usage charts
  - _create_vm_box() # Beautiful VM representations
```

#### Natural Language Processing:
```python
# Smart query parsing examples:
"show mysql servers" ‚Üí filter: {name: "mysql"}
"vms with 8gb ram" ‚Üí filter: {min_memory: 8192}
"running ubuntu 22.04" ‚Üí filter: {status: "running", os: "ubuntu 22.04"}
"vm 203" ‚Üí filter: {id: 203}
```

### üêç Python Migration Complete
1. **Modern Python Stack**
   - Python 3.11+ with full type hints
   - UV package manager for fast dependency resolution
   - Async/await architecture throughout
   - Production-ready error handling

2. **MCP Implementation**
   - WebSocket transport (port 8765)
   - stdio transport for Claude Desktop
   - Tool registration system
   - Comprehensive Proxmox integration

3. **Testing Infrastructure**
   - pytest with async support
   - 59+ test cases with high coverage
   - Mock fixtures for Proxmox API
   - Integration and unit test separation

### üìã Next Priorities

1. **Manual Testing of Current Features** (Immediate)
   - Test natural language queries with AI chat client
   - Verify hardware discovery (MI50 GPU detection)
   - Test deployment suggestions
   - Validate all discovery commands work as expected
   
   **Test Commands:**
   ```bash
   # Discovery Tests
   "list nodes"
   "show vms"
   "running ubuntu servers"
   "vm 203"
   "mysql servers"
   
   # Hardware Tests  
   "discover hardware"
   "show gpus"
   
   # AI Suggestions
   "suggest deployment for ai training"
   "optimize vm placement"
   
   # Visualization
   "generate diagram"
   ```

2. **VM Creation & Management Tools** (Next Phase)
   - Create VMs from templates with resource allocation
   - Modify VM resources (CPU, memory, disk)
   - Start/stop/restart VM operations
   - Clone and template management

3. **Ansible Integration**
   - Execute playbooks on target VMs
   - Service deployment automation
   - Configuration management
   - Post-deployment validation

4. **Service Deployment Templates**
   - Ollama with GPU passthrough
   - Docker/Kubernetes clusters
   - Database servers (MySQL, PostgreSQL)
   - Web services (Nginx, Apache)

5. **Enhanced Security**
   - Network isolation tools
   - Firewall rule management
   - SSL certificate automation
   - Security scanning integration

6. **Multi-Node Support**
   - Cluster-wide resource management
   - Load balancing across nodes
   - High availability configurations
   - Distributed service deployment

### üîß CI/CD Implementation Plan

#### 1. GitHub Actions Workflow (Python)
Create `.github/workflows/ci.yml`:
```yaml
name: CI/CD Pipeline
on:
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]

jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - uses: actions/setup-python@v4
        with:
          python-version: '3.11'
      - name: Install uv
        run: curl -LsSf https://astral.sh/uv/install.sh | sh
      - name: Install dependencies
        run: uv sync
      - name: Run tests
        run: uv run pytest
      - uses: actions/upload-artifact@v3
        if: always()
        with:
          name: coverage-report
          path: htmlcov/

  build:
    needs: test
    runs-on: ubuntu-latest
    if: github.event_name == 'push' && github.ref == 'refs/heads/main'
    steps:
      - uses: actions/checkout@v3
      - uses: docker/setup-buildx-action@v2
      - uses: docker/login-action@v2
        with:
          username: ${{ secrets.DOCKER_USERNAME }}
          password: ${{ secrets.DOCKER_TOKEN }}
      - uses: docker/build-push-action@v4
        with:
          push: true
          tags: |
            yourusername/ansible-mcp-server:latest
            yourusername/ansible-mcp-server:${{ github.sha }}
```

#### 2. Dockerfile for Python
Create a production-ready Dockerfile:
```dockerfile
FROM python:3.11-slim
WORKDIR /app

# Install system dependencies
RUN apt-get update && apt-get install -y \
    ansible \
    openssh-client \
    git \
    && rm -rf /var/lib/apt/lists/*

# Install uv
RUN curl -LsSf https://astral.sh/uv/install.sh | sh

# Copy project files
COPY pyproject.toml uv.lock ./
RUN uv sync --frozen --no-dev

COPY . .

EXPOSE 3000
CMD ["uv", "run", "python", "main.py"]
```

#### 3. Docker Compose for Local Testing
```yaml
version: '3.8'
services:
  ansible-mcp:
    build: .
    volumes:
      - ./ansible:/ansible
      - ~/.ssh:/root/.ssh:ro
    environment:
      - ANSIBLE_HOST_KEY_CHECKING=False
```

### üß™ Python Testing Strategy
- Test framework: pytest
- Async testing: pytest-asyncio
- Mocking: unittest.mock and pytest-mock
- Coverage: pytest-cov
- Type checking: mypy
- Linting: ruff

### üöÄ MVP Priority Features (Linux-First)
1. **Core MCP Implementation** - Get basic Proxmox/Ansible tools working on Linux
2. **Inventory Discovery** - Auto-discover Proxmox resources
3. **Template Management** - VM creation from templates
4. **Basic Testing** - Ensure core functionality works on Linux
5. **WebSocket + Stdio Transports** - Support for various AI clients

## üì¶ Post-MVP Features
1. **GitHub Repository Deployment**
   - Deploy applications directly from GitHub repos
   - Support for docker-compose, Ansible playbooks, Terraform configs
   - Auto-detect deployment type from repo structure
   - Clone ‚Üí Configure ‚Üí Deploy workflow
   - Example: `deploy-from-github repo="user/awesome-app" vm="web-server"`

2. **Transport Wrappers**
   - Proxmox addon wrapper
   - OpenAI/Anthropic API compatibility
   - Home Assistant integration
   - CLI wrapper for terminal use

3. **Cross-Platform Support**
   - Windows support for Ansible execution
   - macOS compatibility
   - Platform-specific adaptations

4. **Terraform Integration** (When Needed)
   - For complex multi-VM deployments (e.g., MCP + Ollama + Web UI stack)
   - State management for infrastructure as code
   - Provider-agnostic resource definitions
   - Examples: K8s clusters, HA WordPress, monitoring stacks
   - Separation: Terraform for infrastructure, Ansible for configuration

### üìù Important Notes
- Using uv for fast, reliable Python package management
- Python 3.11+ for modern async/await and type hints
- Main branch, not master
- Don't commit .claude folder (contains permissions)
- Follow PEP 8 and use type hints throughout

### üîç Key Files to Remember
- `/pyproject.toml` - Python project configuration
- `/main.py` - MCP server entry point
- `/tools/` - MCP tool implementations
- `/utils/` - Shared utilities
- `/.gitignore` - Includes .claude/
- `/uv.lock` - Locked dependencies

### üí° Next Tasks
1. Implement core MCP server structure in Python
2. Create discovery tools for Proxmox inventory
3. Implement execution tools with Ansible integration
4. Set up pytest test suite
5. Create Python-based CI/CD pipeline
6. Document Python implementation decisions

### üîê Security Reminders
- Never commit .claude folder
- Use GitHub secrets for Docker Hub credentials
- Consider separate permissions for CI/CD
- Review Ansible vault setup for sensitive data

## üèÜ Project Achievements Summary

### ‚úÖ What's Working Now:
1. **Complete Proxmox Discovery**
   - List all nodes, VMs, storage, networks, templates
   - Hardware detection including GPU classification
   - Natural language filtering ("show mysql servers", "vms with 8gb")
   - Real-time inventory with caching

2. **AI-Powered Intelligence**
   - Deployment suggestions based on workload type
   - Node scoring algorithm for optimal placement
   - GPU-aware recommendations (MI50 for AI workloads)
   - Resource optimization suggestions

3. **Visual Infrastructure Management**
   - ASCII topology diagrams
   - Resource utilization charts
   - GPU allocation maps
   - Infrastructure relationships

4. **Security & Authentication**
   - Encrypted credential storage
   - API token support (no timeout)
   - Profile management (dev/prod/staging)
   - Secure wizard-based setup

5. **Developer Experience**
   - Natural language interface
   - WebSocket and stdio transports
   - Comprehensive test coverage (59+ tests)
   - Type-safe Python implementation

### üéØ Current Capabilities:
```bash
# Discovery Commands
"list nodes"                    ‚Üí Show Proxmox cluster nodes
"show vms"                     ‚Üí List all virtual machines
"running ubuntu servers"       ‚Üí Filter VMs by status and OS
"vm 203"                       ‚Üí Get specific VM details
"vms with 8gb ram"            ‚Üí Filter by resources
"mysql servers"               ‚Üí Find VMs by service type

# Hardware Intelligence
"discover hardware"           ‚Üí GPU, CPU, storage detection
"show gpus"                   ‚Üí List GPU capabilities
"suggest deployment for ai"   ‚Üí Get optimal node for workload
"optimize vm placement"       ‚Üí Migration recommendations

# VM Creation & Management (COMPLETE)
"create vm jenkins-server"    ‚Üí Create VM with intelligent node placement
"create vm dev-vm cores=4 memory_gb=8" ‚Üí Custom resource allocation
"create vm docker-host install_docker=true" ‚Üí Pre-configure services
"create vm ai-server template_id=9000" ‚Üí Use specific template
"start vm 203"                ‚Üí Start a stopped VM
"stop vm 203"                 ‚Üí Graceful shutdown of VM
"stop vm 203 force=true"      ‚Üí Force stop VM
"delete vm 203"               ‚Üí Delete VM permanently
"get vm status 203"           ‚Üí Get detailed VM status and IP

# Visualization
"generate diagram"            ‚Üí Full infrastructure visualization
"topology chart"              ‚Üí Network layout diagram
"resource utilization"        ‚Üí CPU/memory usage charts

# Configuration
"setup proxmox"              ‚Üí Interactive setup wizard
"create token"               ‚Üí Generate API token
"test connection"            ‚Üí Verify Proxmox access
```

### üìà Project Metrics:
- **Lines of Code**: 11,000+ additions
- **Test Coverage**: 105+ test cases (78 passing, 14 new VM creation tests)
- **Tools Implemented**: 15 MCP tools (10 discovery + 5 VM management)
- **Features**: Hardware detection, AI suggestions, visualization, VM creation
- **Architecture**: Async Python with type safety and cloud-init integration

---

**Current Status**: Infrastructure Intelligence + VM Management Platform is complete. AI agents can now discover resources, create VMs with intelligent placement, and manage full VM lifecycle (start/stop/delete/status). Ready for Ansible service deployment integration.
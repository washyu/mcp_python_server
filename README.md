# Minimal MCP Hello World Setup

A minimal Model Context Protocol (MCP) implementation with a Hello World tool integrated with Ollama AI and a React web client.

## ğŸš€ Quick Start

1. **Start the services:**
   ```bash
   docker-compose -f docker-compose.minimal.yml up -d
   ```

2. **Start the React web client:**
   ```bash
   cd web-client/minimal-chat
   npm install
   npm run dev
   ```

3. **Open your browser:**
   - Navigate to http://localhost:5175
   - Type "hello" to trigger the MCP tool
   - Watch Ollama AI respond with the MCP tool output

## ğŸ—ï¸ Architecture

- **ğŸ¤– Ollama (Docker)**: `localhost:11434` with llama3 model
- **ğŸ”§ MCP Server**: `localhost:3001` with hello_world tool
- **ğŸ’» React Web Client**: `localhost:5175` with proxy to MCP server

## ğŸ”§ Components

### MCP Server (`chat_server_direct.py`)
- Direct implementation of `hello_world_tool()` function
- Starlette web server with streaming chat endpoint
- Detects "hello" in messages and calls MCP tool
- Integrates tool response into Ollama prompt

### Docker Setup (`docker-compose.minimal.yml`)
- **ollama**: Runs ollama/ollama with llama3 model
- **mcp-minimal**: Python server with MCP integration
- **Networking**: Bridge network for service communication

### React Web Client (`web-client/minimal-chat/`)
- TypeScript React app with streaming chat interface
- Vite proxy configuration for MCP server integration
- Server-Sent Events (SSE) for real-time responses
- Violet chat bubbles for AI responses

## ğŸ§ª Test the Flow

1. User types: "hello there!"
2. MCP server detects "hello" â†’ calls `hello_world_tool()`
3. Tool returns: "Hello from the Homelab MCP server"
4. Ollama AI receives prompt with tool response
5. AI generates response mentioning the MCP tool output
6. Web client displays streaming response

## ğŸ“ Project Structure

```
mcp_python_server/
â”œâ”€â”€ chat_server_direct.py           # MCP server with hello_world tool
â”œâ”€â”€ docker-compose.minimal.yml      # Docker services
â”œâ”€â”€ pyproject.toml                  # Python dependencies
â””â”€â”€ web-client/minimal-chat/        # React web client
    â”œâ”€â”€ src/App.tsx                 # Main React component
    â”œâ”€â”€ src/App.css                 # Styling (violet bubbles)
    â””â”€â”€ vite.config.ts              # Proxy configuration
```

## âœ… Working Features

- âœ… **MCP Tool Integration**: hello_world tool called automatically
- âœ… **Ollama AI Integration**: AI uses tool output in responses  
- âœ… **Streaming Responses**: Real-time chat with SSE
- âœ… **Docker Deployment**: Containerized Ollama and MCP server
- âœ… **Web Interface**: Clean React UI with proper styling
- âœ… **End-to-End Flow**: Complete Ollama â†” MCP â†” Web Client flow

Perfect for learning MCP concepts and building more complex integrations!
"""
Infrastructure visualization tool for creating diagrams from Proxmox inventory.
"""

import json
from typing import Dict, Any, List
from pathlib import Path


class InfrastructureVisualizer:
    """Generate visual diagrams from Proxmox infrastructure data."""
    
    def __init__(self, inventory_path: str = None):
        self.inventory_path = inventory_path or "inventory/proxmox-resources.json"
        self.inventory = self._load_inventory()
    
    def _load_inventory(self) -> Dict[str, Any]:
        """Load inventory from JSON file."""
        try:
            with open(self.inventory_path, 'r') as f:
                return json.load(f)
        except FileNotFoundError:
            return {"nodes": [], "vms": [], "storage": [], "networks": [], "templates": []}
    
    def generate_topology_diagram(self) -> str:
        """Generate ASCII topology diagram."""
        nodes = self.inventory.get("nodes", [])
        vms = self.inventory.get("vms", [])
        storage = self.inventory.get("storage", [])
        networks = self.inventory.get("networks", [])
        
        # Parse node data (handle string representation)
        node_info = self._parse_node_data(nodes[0] if nodes else None)
        
        diagram = []
        
        # Header
        diagram.extend([
            "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”",
            "â”‚                            PROXMOX CLUSTER                                 â”‚",
            "â”‚                         192.168.10.200 (Host)                             â”‚",
            "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜",
            "                                      â”‚",
            "                                      â–¼"
        ])
        
        # Node details
        diagram.extend([
            "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”",
            f"â”‚                              NODE: {node_info['name']:<31} â”‚",
            f"â”‚                              Status: {node_info['status'].upper():<29} â”‚",
            f"â”‚                              Uptime: {node_info['uptime']:<29} â”‚",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤",
            "â”‚  ğŸ–¥ï¸  HARDWARE SPECIFICATIONS                                               â”‚",
            f"â”‚   CPU: {node_info['cpu_spec']:<64} â”‚",
            f"â”‚   RAM: {node_info['ram_spec']:<64} â”‚",
            f"â”‚   DISK: {node_info['disk_spec']:<63} â”‚",
            "â”‚   GPU: AMD Radeon Instinct MI50 (16GB HBM2) ğŸ¯ AI-CAPABLE                 â”‚",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤",
            "â”‚  ğŸ’¾ STORAGE POOLS                                                          â”‚"
        ])
        
        # Storage pools
        for pool in storage[:3]:  # Show first 3 pools
            pool_name = pool.get("storage", "unknown")
            pool_path = pool.get("path", pool.get("content", ""))
            diagram.append(f"â”‚   â”œâ”€â”€ {pool_name} ({pool_path[:50]})")
        
        # Network interfaces
        diagram.extend([
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤",
            "â”‚  ğŸŒ NETWORK INTERFACES                                                     â”‚"
        ])
        
        for net in networks[:3]:  # Show first 3 networks
            iface = net.get("iface", "unknown")
            addr = net.get("address", net.get("cidr", ""))
            if addr:
                diagram.append(f"â”‚   â”œâ”€â”€ {iface} ({addr}) - Network Interface")
            else:
                diagram.append(f"â”‚   â”œâ”€â”€ {iface} (Physical Interface)")
        
        diagram.extend([
            "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜",
            "                                      â”‚",
            "                                      â–¼"
        ])
        
        # VM section
        running_vms = [vm for vm in vms if vm.get("status") == "running"]
        stopped_vms = [vm for vm in vms if vm.get("status") == "stopped"]
        templates = [vm for vm in vms if vm.get("template") == 1]
        
        diagram.extend([
            "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”",
            f"â”‚                          VIRTUAL MACHINES ({len(vms)} Total)" + " " * (24 - len(str(len(vms)))) + "â”‚",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤",
            "â”‚                                                                             â”‚",
            f"â”‚  ğŸŸ¢ RUNNING VMs ({len(running_vms)})" + " " * (56 - len(str(len(running_vms)))) + "â”‚"
        ])
        
        # Running VMs
        for vm in running_vms:
            vm_box = self._create_vm_box(vm, "running")
            diagram.extend(vm_box)
        
        diagram.extend([
            "â”‚                                                                             â”‚",
            f"â”‚  ğŸ”´ STOPPED VMs ({len(stopped_vms)})" + " " * (56 - len(str(len(stopped_vms)))) + "â”‚"
        ])
        
        # Stopped VMs (show first 4)
        for vm in stopped_vms[:4]:
            vm_box = self._create_vm_box(vm, "stopped")
            diagram.extend(vm_box)
        
        if templates:
            diagram.extend([
                "â”‚                                                                             â”‚",
                f"â”‚  ğŸ“‹ TEMPLATE ({len(templates)})" + " " * (58 - len(str(len(templates)))) + "â”‚"
            ])
            
            for template in templates:
                vm_box = self._create_vm_box(template, "template")
                diagram.extend(vm_box)
        
        diagram.append("â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜")
        
        return "\n".join(diagram)
    
    def _parse_node_data(self, node_data) -> Dict[str, str]:
        """Parse node data from string representation."""
        if not node_data:
            return {
                "name": "unknown",
                "status": "unknown", 
                "uptime": "unknown",
                "cpu_spec": "unknown",
                "ram_spec": "unknown",
                "disk_spec": "unknown"
            }
        
        import re
        
        # Extract values from string representation
        node_str = str(node_data)
        
        # Parse node info
        name_match = re.search(r"node='([^']*)'", node_str)
        status_match = re.search(r"status='([^']*)'", node_str)
        cpu_match = re.search(r"cpu=([0-9.]+)", node_str)
        maxcpu_match = re.search(r"maxcpu=([0-9]+)", node_str)
        mem_match = re.search(r"mem=([0-9]+)", node_str)
        maxmem_match = re.search(r"maxmem=([0-9]+)", node_str)
        disk_match = re.search(r"disk=([0-9]+)", node_str)
        maxdisk_match = re.search(r"maxdisk=([0-9]+)", node_str)
        uptime_match = re.search(r"uptime=([0-9]+)", node_str)
        
        name = name_match.group(1) if name_match else "unknown"
        status = status_match.group(1) if status_match else "unknown"
        
        # Calculate specs
        cpu_usage = float(cpu_match.group(1)) * 100 if cpu_match else 0
        max_cpu = int(maxcpu_match.group(1)) if maxcpu_match else 0
        cpu_spec = f"{max_cpu} cores ({cpu_usage:.1f}% utilization)"
        
        mem_used = int(mem_match.group(1)) / (1024**3) if mem_match else 0
        max_mem = int(maxmem_match.group(1)) / (1024**3) if maxmem_match else 0
        ram_spec = f"{max_mem:.1f}GB total ({mem_used:.1f}GB used, {max_mem - mem_used:.1f}GB free)"
        
        disk_used = int(disk_match.group(1)) / (1024**3) if disk_match else 0
        max_disk = int(maxdisk_match.group(1)) / (1024**3) if maxdisk_match else 0
        disk_spec = f"{max_disk:.1f}GB total ({disk_used:.1f}GB used, {max_disk - disk_used:.1f}GB free)"
        
        uptime_hours = int(uptime_match.group(1)) / 3600 if uptime_match else 0
        uptime_str = f"{uptime_hours:.1f} hours"
        
        return {
            "name": name,
            "status": status,
            "uptime": uptime_str,
            "cpu_spec": cpu_spec,
            "ram_spec": ram_spec,
            "disk_spec": disk_spec
        }
    
    def _create_vm_box(self, vm: Dict[str, Any], vm_type: str) -> List[str]:
        """Create ASCII box for a VM."""
        vm_id = vm.get("vmid", "?")
        name = vm.get("name", "Unknown")
        cpus = vm.get("cpus", 0)
        maxmem_gb = vm.get("maxmem", 0) / (1024**3)
        maxdisk_gb = vm.get("maxdisk", 0) / (1024**3)
        
        # Determine VM category and emoji
        category_info = self._categorize_vm(name, vm.get("tags", ""))
        
        box = [
            "â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚",
            f"â”‚  â”‚ VM {vm_id}: {name:<35} {category_info['emoji']} {category_info['category']:<12} â”‚   â”‚"
        ]
        
        if vm_type != "template":
            box.extend([
                f"â”‚  â”‚ â”œâ”€â”€ CPU: {cpus} cores" + (" " * (50 - len(f"CPU: {cpus} cores"))) + "â”‚   â”‚",
                f"â”‚  â”‚ â”œâ”€â”€ RAM: {maxmem_gb:.0f}GB" + (" " * (48 - len(f"RAM: {maxmem_gb:.0f}GB"))) + "â”‚   â”‚"
            ])
            
            if maxdisk_gb > 0:
                box.append(f"â”‚  â”‚ â”œâ”€â”€ Disk: {maxdisk_gb:.0f}GB" + (" " * (47 - len(f"Disk: {maxdisk_gb:.0f}GB"))) + "â”‚   â”‚")
        
        # Add special notes
        if "ollama" in name.lower():
            box.append("â”‚  â”‚ â”œâ”€â”€ GPU: Using MI50 for AI training ğŸ¯" + (" " * 24) + "â”‚   â”‚")
        
        # Add status-specific info
        if vm_type == "running":
            mem_used_gb = vm.get("mem", 0) / (1024**3)
            cpu_usage = vm.get("cpu", 0) * 100
            if mem_used_gb > 0:
                box.append(f"â”‚  â”‚ â”œâ”€â”€ Usage: {cpu_usage:.1f}% CPU, {mem_used_gb:.1f}GB RAM used" + (" " * (20 - len(f"{cpu_usage:.1f}% CPU, {mem_used_gb:.1f}GB RAM used"))) + "â”‚   â”‚")
        elif vm_type == "template":
            box.append("â”‚  â”‚ â””â”€â”€ Status: Base template for cloning" + (" " * 26) + "â”‚   â”‚")
        else:
            box.append(f"â”‚  â”‚ â””â”€â”€ Status: {category_info['description']}" + (" " * (35 - len(category_info['description']))) + "â”‚   â”‚")
        
        box.append("â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚")
        box.append("â”‚                                                                             â”‚")
        
        return box
    
    def _categorize_vm(self, name: str, tags: str) -> Dict[str, str]:
        """Categorize VM based on name and tags."""
        name_lower = name.lower()
        tags_lower = tags.lower()
        
        if "ollama" in name_lower or "ai" in tags_lower:
            return {"emoji": "ğŸ¤–", "category": "AI TRAINING", "description": "LLM inference server"}
        elif "database" in name_lower or "mysql" in name_lower or "mysql" in tags_lower:
            return {"emoji": "ğŸ’¾", "category": "DATABASE", "description": "Database server"}
        elif "jenkins" in name_lower:
            return {"emoji": "ğŸ”„", "category": "CI/CD", "description": "Jenkins automation server"}
        elif "mcp" in name_lower:
            return {"emoji": "ğŸ”§", "category": "INFRASTRUCTURE", "description": "MCP server"}
        elif "dev" in name_lower:
            return {"emoji": "ğŸ”§", "category": "DEVELOPMENT", "description": "Development environment"}
        elif "test" in name_lower:
            return {"emoji": "ğŸ§ª", "category": "TEST", "description": "Testing environment"}
        elif "template" in name_lower:
            return {"emoji": "ğŸ“¦", "category": "TEMPLATE", "description": "VM template"}
        elif "production" in name_lower or "prod" in name_lower:
            return {"emoji": "ğŸš€", "category": "PRODUCTION", "description": "Production server"}
        else:
            return {"emoji": "âš™ï¸", "category": "GENERAL", "description": "General purpose VM"}
    
    def generate_resource_utilization(self) -> str:
        """Generate resource utilization charts."""
        vms = self.inventory.get("vms", [])
        
        # Calculate total allocations
        total_cpu_allocated = sum(vm.get("cpus", 0) for vm in vms)
        total_ram_allocated = sum(vm.get("maxmem", 0) for vm in vms) / (1024**3)
        
        # Available resources (from node data)
        node_data = self.inventory.get("nodes", [])
        if node_data:
            node_str = str(node_data[0])
            import re
            maxcpu_match = re.search(r"maxcpu=([0-9]+)", node_str)
            maxmem_match = re.search(r"maxmem=([0-9]+)", node_str)
            
            total_cpu_available = int(maxcpu_match.group(1)) if maxcpu_match else 12
            total_ram_available = int(maxmem_match.group(1)) / (1024**3) if maxmem_match else 64
        else:
            total_cpu_available = 12
            total_ram_available = 64
        
        chart = []
        
        # CPU Chart
        chart.extend([
            "## ğŸ“Š Resource Utilization Analysis",
            "",
            "### CPU Distribution",
            f"Total CPU Cores: {total_cpu_available}",
            "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”",
            "â”‚ VM Name         â”‚ Cores   â”‚ Usage Bar                           â”‚",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤"
        ])
        
        # Sort VMs by CPU allocation
        sorted_vms = sorted(vms, key=lambda x: x.get("cpus", 0), reverse=True)
        
        for vm in sorted_vms[:8]:  # Show top 8 VMs
            name = vm.get("name", "Unknown")[:15]
            cpus = vm.get("cpus", 0)
            status = vm.get("status", "unknown")
            
            # Create usage bar (32 chars max)
            bar_length = min(32, int((cpus / total_cpu_available) * 32))
            usage_bar = "â–ˆ" * bar_length
            
            if status == "stopped":
                usage_bar += " (stopped)"
            elif vm.get("template"):
                usage_bar += " (template)"
            
            chart.append(f"â”‚ {name:<15} â”‚ {cpus} cores â”‚ {usage_bar:<35} â”‚")
        
        # Totals
        overcommit = total_cpu_allocated / total_cpu_available
        chart.extend([
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤",
            f"â”‚ ALLOCATED       â”‚ {total_cpu_allocated} coresâ”‚ {'â–ˆ' * 32}{'â–ˆ' * (int(overcommit) - 1) if overcommit > 1 else ''}â”‚",
            f"â”‚ AVAILABLE       â”‚ {total_cpu_available} coresâ”‚ {'â–ˆ' * 24}                    â”‚",
            f"â”‚ OVERCOMMIT      â”‚ {overcommit:.1f}x    â”‚ Some VMs stopped = fits             â”‚",
            "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜"
        ])
        
        # Memory Chart
        chart.extend([
            "",
            "### Memory Distribution", 
            f"Total Memory: {total_ram_available:.1f}GB",
            "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”",
            "â”‚ VM Name         â”‚ RAM     â”‚ Usage Bar                           â”‚",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤"
        ])
        
        # Sort VMs by memory allocation
        sorted_vms_mem = sorted(vms, key=lambda x: x.get("maxmem", 0), reverse=True)
        
        for vm in sorted_vms_mem[:8]:  # Show top 8 VMs
            name = vm.get("name", "Unknown")[:15]
            maxmem_gb = vm.get("maxmem", 0) / (1024**3)
            mem_used_gb = vm.get("mem", 0) / (1024**3)
            status = vm.get("status", "unknown")
            
            # Create usage bar
            bar_length = min(32, int((maxmem_gb / total_ram_available) * 32))
            usage_bar = "â–ˆ" * bar_length
            
            if status == "running" and mem_used_gb > 0:
                usage_bar += f" ({mem_used_gb:.1f}GB used)"
            elif status == "stopped":
                usage_bar += " (stopped)"
            elif vm.get("template"):
                usage_bar += " (template)"
            
            chart.append(f"â”‚ {name:<15} â”‚ {maxmem_gb:.0f}GB    â”‚ {usage_bar:<35} â”‚")
        
        # Memory totals
        mem_overcommit = total_ram_allocated / total_ram_available
        chart.extend([
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤",
            f"â”‚ ALLOCATED       â”‚ {total_ram_allocated:.0f}GB    â”‚ {'â–ˆ' * 32}{'â–ˆ' * (int(mem_overcommit) - 1) if mem_overcommit > 1 else ''}â”‚",
            f"â”‚ AVAILABLE       â”‚ {total_ram_available:.1f}GB  â”‚ {'â–ˆ' * 24}                    â”‚",
            f"â”‚ OVERCOMMIT      â”‚ {mem_overcommit:.2f}x   â”‚ Some VMs stopped = fits             â”‚",
            "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜"
        ])
        
        return "\n".join(chart)
    
    def generate_full_report(self) -> str:
        """Generate complete infrastructure report."""
        report_parts = [
            "# Proxmox Infrastructure Topology Diagram",
            "",
            "## ğŸ—ï¸ Physical Infrastructure Overview",
            "",
            "```",
            self.generate_topology_diagram(),
            "```",
            "",
            self.generate_resource_utilization(),
            "",
            "## ğŸ¯ AI & GPU Utilization",
            "",
            self._generate_gpu_section(),
            "",
            "## ğŸ’¡ Optimization Recommendations",
            "",
            self._generate_recommendations()
        ]
        
        return "\n".join(report_parts)
    
    def _generate_gpu_section(self) -> str:
        """Generate GPU utilization section."""
        vms = self.inventory.get("vms", [])
        ai_vms = [vm for vm in vms if "ollama" in vm.get("name", "").lower() or "ai" in vm.get("tags", "").lower()]
        
        gpu_section = [
            "```",
            "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”",
            "â”‚                     GPU ALLOCATION MAP                         â”‚",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤",
            "â”‚                                                                 â”‚",
            "â”‚  ğŸ® AMD Radeon Instinct MI50 (16GB HBM2)                       â”‚",
            "â”‚  â”œâ”€â”€ Purpose: AI Training & Inference                          â”‚",
            "â”‚  â”œâ”€â”€ Capabilities: OpenCL, ROCm, HIP                           â”‚",
            "â”‚  â”œâ”€â”€ Memory: 16GB High Bandwidth Memory                        â”‚",
            "â”‚  â””â”€â”€ Current Allocation:                                       â”‚"
        ]
        
        if ai_vms:
            for vm in ai_vms:
                name = vm.get("name", "Unknown")
                vm_id = vm.get("vmid", "?")
                status = vm.get("status", "unknown").upper()
                
                gpu_section.extend([
                    "â”‚      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚",
                    f"â”‚      â”‚ ğŸ¤– {name:<31} (VM {vm_id}){'â”‚   â”‚':<15}",
                    f"â”‚      â”‚ â”œâ”€â”€ Status: {status:<31}{'â”‚   â”‚':<15}",
                    "â”‚      â”‚ â”œâ”€â”€ GPU Usage: ACTIVE                              â”‚   â”‚",
                    "â”‚      â”‚ â”œâ”€â”€ Purpose: LLM inference                         â”‚   â”‚",
                    "â”‚      â”‚ â””â”€â”€ Optimization: 100% GPU node utilization       â”‚   â”‚",
                    "â”‚      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚"
                ])
        else:
            gpu_section.extend([
                "â”‚      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚",
                "â”‚      â”‚ ğŸ’¤ GPU Currently Available                         â”‚   â”‚",
                "â”‚      â”‚ â””â”€â”€ Ready for AI workload deployment               â”‚   â”‚",
                "â”‚      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚"
            ])
        
        gpu_section.extend([
            "â”‚                                                                 â”‚",
            "â”‚  ğŸ’¡ OPTIMIZATION OPPORTUNITIES:                                â”‚",
            "â”‚  â”œâ”€â”€ Move non-AI VMs to free up GPU node                      â”‚",
            "â”‚  â”œâ”€â”€ Consolidate AI workloads on GPU-enabled node             â”‚",
            "â”‚  â””â”€â”€ Reserve GPU node exclusively for AI training             â”‚",
            "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜",
            "```"
        ])
        
        return "\n".join(gpu_section)
    
    def _generate_recommendations(self) -> str:
        """Generate optimization recommendations."""
        vms = self.inventory.get("vms", [])
        running_vms = [vm for vm in vms if vm.get("status") == "running"]
        
        recommendations = [
            "Based on current infrastructure analysis:",
            "",
            "### âœ… OPTIMAL PLACEMENTS:",
            "1. **AI Training Workloads** â†’ Node 'proxmox' (has MI50 GPU)",
            "2. **Database Workloads** â†’ Node 'proxmox' (sufficient resources)",
            "3. **Web Services** â†’ Node 'proxmox' (underutilized)",
            "",
            "### âš¡ OPTIMIZATION OPPORTUNITIES:",
            "1. **GPU Consolidation**: Move non-AI VMs to maximize GPU node efficiency"
        ]
        
        # Calculate available resources
        node_data = self.inventory.get("nodes", [])
        if node_data:
            node_str = str(node_data[0])
            import re
            mem_match = re.search(r"mem=([0-9]+)", node_str)
            maxmem_match = re.search(r"maxmem=([0-9]+)", node_str)
            
            if mem_match and maxmem_match:
                mem_used = int(mem_match.group(1)) / (1024**3)
                max_mem = int(maxmem_match.group(1)) / (1024**3)
                available_mem = max_mem - mem_used
                
                recommendations.append(f"2. **Resource Rebalancing**: {available_mem:.0f}GB RAM available for new workloads")
        
        recommendations.extend([
            "3. **Template Utilization**: VM 9000 ready for rapid deployment",
            "",
            "### ğŸš€ SCALING POTENTIAL:",
            f"- **Can Deploy**: {len([vm for vm in vms if vm.get('status') == 'stopped'])} stopped VMs can be optimized",
            "- **GPU Capacity**: 1 MI50 available for AI expansion",
            "- **Network Ready**: Bridge configured for VM networking",
            "",
            "This infrastructure is **perfectly positioned** for AI workload expansion with the MI50 GPU as the crown jewel! ğŸ¯"
        ])
        
        return "\n".join(recommendations)


def generate_infrastructure_diagram(inventory_path: str = None) -> str:
    """Generate infrastructure diagram from inventory data."""
    visualizer = InfrastructureVisualizer(inventory_path)
    return visualizer.generate_full_report()


if __name__ == "__main__":
    # Test the visualizer
    print(generate_infrastructure_diagram())